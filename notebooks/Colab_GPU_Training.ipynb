{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0a3c85",
   "metadata": {},
   "source": [
    "# üöÄ Sales Churn Prediction - GPU Training Pipeline (Google Colab)\n",
    "\n",
    "## Complete ML Pipeline with GPU Acceleration\n",
    "\n",
    "This notebook trains an XGBoost churn prediction model using:\n",
    "- ‚úÖ **GPU Acceleration** (CUDA)\n",
    "- ‚úÖ **Pre-computed Optimal Hyperparameters** (no Optuna needed)\n",
    "- ‚úÖ **MLflow Experiment Tracking**\n",
    "- ‚úÖ **Production-Ready Model**\n",
    "\n",
    "### ‚öôÔ∏è Setup Instructions:\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí **GPU**\n",
    "2. **Run all cells** in order\n",
    "3. **Download trained model** at the end\n",
    "\n",
    "Expected Runtime: **~3-5 minutes** with GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dd75fe",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Check GPU Availability\n",
    "\n",
    "Verify that GPU is enabled and available for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "# Verify CUDA for XGBoost\n",
    "import subprocess\n",
    "result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "if 'Tesla' in result.stdout or 'GPU' in result.stdout:\n",
    "    print(\"\\n‚úì GPU is available and ready for training!\")\n",
    "else:\n",
    "    print(\"\\n‚ö† GPU not detected. Please enable GPU in Runtime settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ec777",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone Repository & Setup Project\n",
    "\n",
    "Clone your project from GitHub or upload files manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee93044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Clone from GitHub (recommended)\n",
    "!git clone https://github.com/your-username/sales-data-churn.git\n",
    "%cd sales-data-churn\n",
    "\n",
    "# Option B: Upload manually (uncomment if needed)\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # Upload your project zip\n",
    "# !unzip sales-data-churn.zip\n",
    "# %cd sales-data-churn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d147bd74",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Install Required Packages\n",
    "\n",
    "Install XGBoost (with GPU support), MLflow, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q xgboost scikit-learn pandas numpy mlflow optuna\n",
    "\n",
    "# Verify XGBoost GPU support\n",
    "import xgboost as xgb\n",
    "print(f\"XGBoost version: {xgb.__version__}\")\n",
    "print(\"GPU support:\", xgb.build_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7cecb2",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Verify Data Files\n",
    "\n",
    "Check that your training and test data are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bba1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data files\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"data/raw/train.csv\",\n",
    "    \"test\": \"data/raw/test.csv\",\n",
    "}\n",
    "\n",
    "print(\"Checking data files:\")\n",
    "for name, path in data_files.items():\n",
    "    if os.path.exists(path):\n",
    "        print(f\"  ‚úì {name}: {path}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {name}: {path} NOT FOUND\")\n",
    "        \n",
    "# If files are missing, upload them\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()  # Upload train.csv and test.csv\n",
    "# !mkdir -p data/raw\n",
    "# !mv train.csv data/raw/\n",
    "# !mv test.csv data/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ddd73",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ View Pipeline Configuration\n",
    "\n",
    "Review the pre-configured hyperparameters and training settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fe34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Pre-computed optimal hyperparameters (from 250 Optuna trials)\n",
    "best_params = {\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"lambda\": 0.00032762263951052436,\n",
    "    \"alpha\": 0.00017370640229832804,\n",
    "    \"max_depth\": 7,\n",
    "    \"eta\": 0.2960673713462837,\n",
    "    \"gamma\": 0.00017131007397068948,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7605678991335877,\n",
    "    \"colsample_bytree\": 0.9988324896159033,\n",
    "    \"colsample_bylevel\": 0.7777131466076425,\n",
    "    \"n_estimators\": 900,\n",
    "}\n",
    "\n",
    "print(\"üìä Training Configuration:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Model: XGBoost Classifier\")\n",
    "print(\"Device: CUDA (GPU)\")\n",
    "print(\"Optimize Metric: Recall\")\n",
    "print(\"Threshold: 0.35 (for predictions)\")\n",
    "print(\"\\nüéØ Hyperparameters:\")\n",
    "print(json.dumps(best_params, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c14c0c",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Run Complete Training Pipeline\n",
    "\n",
    "Execute the full ML pipeline with GPU acceleration.\n",
    "\n",
    "This will:\n",
    "1. Load and validate data\n",
    "2. Preprocess features\n",
    "3. Train XGBoost model on GPU\n",
    "4. Track experiments with MLflow\n",
    "5. Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29d726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the GPU-optimized pipeline\n",
    "!python scripts/colab_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d53bacf",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ View Training Results\n",
    "\n",
    "Load and display the training metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Find the trained model\n",
    "model_dir = \"models\"\n",
    "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')]\n",
    "\n",
    "if model_files:\n",
    "    model_path = os.path.join(model_dir, model_files[0])\n",
    "    print(f\"‚úì Model found: {model_path}\")\n",
    "    \n",
    "    # Load model (optional - just to verify)\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(f\"  Model type: {type(model).__name__}\")\n",
    "    print(f\"  Number of features: {model.n_features_in_}\")\n",
    "    print(f\"  Number of trees: {model.n_estimators}\")\n",
    "else:\n",
    "    print(\"‚ö† No model file found. Check pipeline execution above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac17ad5",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Download Trained Model\n",
    "\n",
    "Download your trained model to local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the trained model\n",
    "from google.colab import files\n",
    "\n",
    "model_dir = \"models\"\n",
    "model_files = [f for f in os.listdir(model_dir) if f.endswith('.pkl')]\n",
    "\n",
    "if model_files:\n",
    "    for model_file in model_files:\n",
    "        model_path = os.path.join(model_dir, model_file)\n",
    "        print(f\"Downloading: {model_path}\")\n",
    "        files.download(model_path)\n",
    "    print(\"‚úì Download complete!\")\n",
    "else:\n",
    "    print(\"‚ö† No model files to download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080f25c",
   "metadata": {},
   "source": [
    "## 9Ô∏è‚É£ Optional: Save to Google Drive\n",
    "\n",
    "Mount Google Drive and save all outputs for persistence across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af98fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (optional)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Copy models and outputs to Drive\n",
    "import shutil\n",
    "drive_path = \"/content/drive/MyDrive/churn_models\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(drive_path, exist_ok=True)\n",
    "    \n",
    "    # Copy models\n",
    "    if os.path.exists(\"models\"):\n",
    "        shutil.copytree(\"models\", f\"{drive_path}/models\", dirs_exist_ok=True)\n",
    "        print(f\"‚úì Models saved to: {drive_path}/models\")\n",
    "    \n",
    "    # Copy MLflow runs\n",
    "    if os.path.exists(\"mlruns\"):\n",
    "        shutil.copytree(\"mlruns\", f\"{drive_path}/mlruns\", dirs_exist_ok=True)\n",
    "        print(f\"‚úì MLflow experiments saved to: {drive_path}/mlruns\")\n",
    "        \n",
    "    print(\"\\n‚úì All outputs saved to Google Drive!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† Error saving to Drive: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae52c3",
   "metadata": {},
   "source": [
    "## ‚úÖ Pipeline Complete!\n",
    "\n",
    "### üéâ What You've Accomplished:\n",
    "- ‚úì Trained an XGBoost model with GPU acceleration\n",
    "- ‚úì Used pre-optimized hyperparameters (900 trees)\n",
    "- ‚úì Achieved optimal recall for churn prediction\n",
    "- ‚úì Tracked experiments with MLflow\n",
    "- ‚úì Downloaded production-ready model\n",
    "\n",
    "### üìä Next Steps:\n",
    "1. **Test the model** on holdout data\n",
    "2. **Deploy to production** using the downloaded .pkl file\n",
    "3. **Monitor performance** and retrain as needed\n",
    "\n",
    "### üîß Customization:\n",
    "To modify training parameters, edit `scripts/colab_pipeline.py`:\n",
    "- Change `THRESHOLD_VALUE` for different precision/recall tradeoff\n",
    "- Adjust `PREPROCESSING_STRATEGY` for data handling\n",
    "- Modify `BEST_PARAMS` to try different hyperparameters\n",
    "\n",
    "---\n",
    "\n",
    "**Training Time:** ~3-5 minutes with GPU  \n",
    "**Model Performance:** Optimized for maximum recall (catching churners)  \n",
    "**GPU Utilization:** Full CUDA acceleration for XGBoost"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
