name: Modular Pipeline CI Test

on:
  push:
    branches: [ main, dev ]
  pull_request:
    branches: [ main, dev ]
  workflow_dispatch:  # Allow manual trigger

# This workflow tests that all pipeline stages work correctly
# Uses minimal parameters (5 trials, 2 runs) for fast CI testing
# Does NOT save production models - artifacts expire after 1 day

jobs:
  # Job 1: Prepare data
  prepare-data:
    name: Prepare Test Data
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas scikit-learn

      - name: Prepare dummy data
        run: |
          python scripts/prepare_ci_data.py

      - name: Verify data files created
        run: |
          echo "Checking data files..."
          ls -lh data/raw/train.csv
          ls -lh data/raw/test.csv
          echo "Train samples:"
          wc -l data/raw/train.csv
          echo "Test samples:"
          wc -l data/raw/test.csv

      - name: Upload data artifacts
        uses: actions/upload-artifact@v4
        with:
          name: test-data
          path: |
            data/raw/train.csv
            data/raw/test.csv
          retention-days: 1

  # Job 2: Test Stage 1 - Load Data
  test-stage-load:
    name: Stage 1 - Load Data
    runs-on: ubuntu-latest
    needs: prepare-data
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download test data
        uses: actions/download-artifact@v4
        with:
          name: test-data
          path: data/raw/

      - name: Verify data files
        run: |
          echo "Checking downloaded data files..."
          ls -lh data/raw/
          test -f data/raw/train.csv || { echo "Error: train.csv not found!"; exit 1; }
          test -f data/raw/test.csv || { echo "Error: test.csv not found!"; exit 1; }

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Load Stage
        run: |
          python scripts/modular_pipeline.py --stages load
          
      - name: Verify load output
        run: |
          echo "Checking pipeline state..."
          ls -lh outputs/pipeline_state/

      - name: Upload stage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stage-load
          path: outputs/pipeline_state/load.pkl
          retention-days: 1

  # Job 3: Test Stage 2 - Validate Data (Optional - can be skipped for speed)
  test-stage-validate:
    name: Stage 2 - Validate Data
    runs-on: ubuntu-latest
    needs: test-stage-load
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download previous artifacts
        uses: actions/download-artifact@v4
        with:
          name: stage-load
          path: outputs/pipeline_state/

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Validate Stage
        run: |
          python scripts/modular_pipeline.py --stages validate

      - name: Upload stage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stage-validate
          path: outputs/pipeline_state/
          retention-days: 1

  # Job 4: Test Stage 3 - Preprocess Data
  test-stage-preprocess:
    name: Stage 3 - Preprocess Data
    runs-on: ubuntu-latest
    needs: test-stage-validate
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download previous artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: stage-*
          path: outputs/pipeline_state/
          merge-multiple: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Preprocess Stage
        run: |
          python scripts/modular_pipeline.py --stages preprocess

      - name: Upload stage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stage-preprocess
          path: outputs/pipeline_state/
          retention-days: 1

  # Job 5: Test Stage 4 - Build Features
  test-stage-features:
    name: Stage 4 - Build Features
    runs-on: ubuntu-latest
    needs: test-stage-preprocess
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download previous artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: stage-*
          path: outputs/pipeline_state/
          merge-multiple: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Features Stage
        run: |
          python scripts/modular_pipeline.py --stages features

      - name: Upload stage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stage-features
          path: outputs/pipeline_state/
          retention-days: 1

  # Job 6: Test Stage 5 - Encode Features
  test-stage-encode:
    name: Stage 5 - Encode Features
    runs-on: ubuntu-latest
    needs: test-stage-features
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download previous artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: stage-*
          path: outputs/pipeline_state/
          merge-multiple: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Encode Stage
        run: |
          python scripts/modular_pipeline.py --stages encode

      - name: Verify processed data
        run: |
          echo "Checking processed data..."
          ls -lh data/processed/

      - name: Upload stage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stage-encode
          path: outputs/pipeline_state/
          retention-days: 1
      
      - name: Upload processed data
        uses: actions/upload-artifact@v4
        with:
          name: processed-data
          path: data/processed/
          retention-days: 1

  # Job 7: Test Stage 6 - Optuna Optimization (Minimal trials)
  test-stage-optuna:
    name: Stage 6 - Optimize Hyperparameters
    runs-on: ubuntu-latest
    needs: test-stage-encode
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download previous artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: stage-*
          path: outputs/pipeline_state/
          merge-multiple: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Optuna Stage (Minimal trials)
        run: |
          python scripts/modular_pipeline.py --stages optuna --n-trials 5

      - name: Upload stage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stage-optuna
          path: outputs/pipeline_state/
          retention-days: 1

  # Job 8: Test Stage 7 - Train Model (Minimal runs)
  test-stage-train:
    name: Stage 7 - Train Model
    runs-on: ubuntu-latest
    needs: test-stage-optuna
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download previous artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: stage-*
          path: outputs/pipeline_state/
          merge-multiple: true

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Train Stage (Minimal runs)
        run: |
          python scripts/modular_pipeline.py --stages train --n-trials 5 --n-runs 2

      - name: Verify MLflow artifacts
        run: |
          echo "Checking MLflow runs..."
          ls -lh mlruns/

      - name: Upload stage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stage-train
          path: outputs/pipeline_state/
          retention-days: 1
      
      - name: Upload MLflow artifacts
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-runs
          path: mlruns/
          retention-days: 1

  # Job 9: Test Stage 8 - Save Model
  test-stage-save:
    name: Stage 8 - Save Model
    runs-on: ubuntu-latest
    needs: test-stage-train
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Download previous artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: stage-*
          path: outputs/pipeline_state/
          merge-multiple: true

      - name: Download MLflow artifacts
        uses: actions/download-artifact@v4
        with:
          name: mlflow-runs
          path: mlruns/

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set PYTHONPATH
        run: echo "PYTHONPATH=$PWD" >> $GITHUB_ENV

      - name: Run Save Stage
        run: |
          python scripts/modular_pipeline.py --stages save

      - name: Verify model saved
        run: |
          echo "Checking if model can be saved (testing only)..."
          ls -lh models/
          if ls models/*.pkl 1> /dev/null 2>&1; then
            echo "✅ Model save stage works correctly!"
            echo "Note: This is a CI test, model not retained."
          else
            echo "❌ Model save failed!"
            exit 1
          fi

  # Job 10: Summary Report
  pipeline-summary:
    name: Pipeline Test Summary
    runs-on: ubuntu-latest
    needs: test-stage-save
    if: always()
    
    steps:
      - name: Pipeline Test Complete
        run: |
          echo "=========================================="
          echo "  MODULAR PIPELINE CI TEST COMPLETE"
          echo "=========================================="
          echo ""
          echo "All stages tested successfully:"
          echo "  ✅ Stage 1: Load Data"
          echo "  ✅ Stage 2: Validate Data"
          echo "  ✅ Stage 3: Preprocess Data"
          echo "  ✅ Stage 4: Build Features"
          echo "  ✅ Stage 5: Encode Features"
          echo "  ✅ Stage 6: Optuna Optimization (5 trials)"
          echo "  ✅ Stage 7: Train Model (2 runs)"
          echo "  ✅ Stage 8: Save Model"
          echo ""
          echo "Test parameters:"
          echo "  - Data: dummy_data.csv (51 samples)"
          echo "  - Split: 70% train / 30% test"
          echo "  - Optuna trials: 5 (minimal for CI)"
          echo "  - MLflow runs: 2 (minimal for CI)"
          echo "  - Metric: recall"
          echo ""
          echo "ℹ️  This is a CI test only."
          echo "ℹ️  No artifacts retained after 1 day."
          echo "ℹ️  Use production pipeline for real models."
