# ============================================================================
# Application Configuration
# ============================================================================

# Application settings
APP_NAME=Churn Prediction API
APP_VERSION=1.0.0
DEBUG=false

# API server settings
API_HOST=0.0.0.0
API_PORT=8000

# ============================================================================
# MLflow Configuration
# ============================================================================

# MLflow tracking URI (local or remote)
MLFLOW_TRACKING_URI=./mlruns

# Option 1: Load specific model by run ID
MLFLOW_RUN_ID=096c396d6abf4a7da6bae24acb8d99fe

# Option 2: Load best model from experiment (comment out MLFLOW_RUN_ID if using this)
# MLFLOW_EXPERIMENT_NAME=Colab_GPU_Training

# ============================================================================
# Model Configuration
# ============================================================================

# Prediction threshold for binary classification
PREDICTION_THRESHOLD=0.5

# Maximum batch size for batch predictions
MAX_BATCH_SIZE=1000

# ============================================================================
# Logging Configuration
# ============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format: json or text
LOG_FORMAT=json

# ============================================================================
# AWS Configuration (for ECS deployment)
# ============================================================================

# AWS region
# AWS_REGION=us-east-1

# S3 bucket for MLflow artifacts (if using S3)
# MLFLOW_S3_BUCKET=my-mlflow-artifacts

# ============================================================================
# Performance Settings
# ============================================================================

# Number of Uvicorn workers (typically set to number of CPU cores)
# WORKERS=1

# Request timeout in seconds
# REQUEST_TIMEOUT=30
