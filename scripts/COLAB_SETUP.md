# Google Colab GPU Training Setup Guide

## ðŸš€ Quick Start (3 Steps)

### Step 1: Enable GPU in Colab
```
Runtime > Change runtime type > Hardware accelerator > GPU
```

### Step 2: Clone Your Repository
In a Colab notebook cell:
```python
# Clone your project
!git clone https://github.com/your-username/sales-data-churn.git
%cd sales-data-churn

# Or upload manually if not on GitHub
from google.colab import files
# Upload your project as zip, then:
# !unzip sales-data-churn.zip
# %cd sales-data-churn
```

### Step 3: Install Dependencies & Run
```python
# Install required packages
!pip install -q xgboost scikit-learn pandas numpy mlflow optuna

# Run the GPU-optimized pipeline
!python scripts/colab_pipeline.py
```

---

## ðŸ“Š What This Pipeline Does

âœ… **Skips Optuna** - Uses pre-computed optimal hyperparameters (saves time & GPU credits)  
âœ… **GPU Training** - Utilizes Colab's CUDA GPU for faster XGBoost training  
âœ… **Single Run** - Trains one optimized model (not multiple experiments)  
âœ… **900 Trees** - XGBoost with n_estimators=900 for maximum performance  
âœ… **Recall Optimized** - Tuned for catching churners (threshold=0.35)  

---

## ðŸ“ File Structure Required

Make sure your project has this structure:
```
sales-data-churn/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/
â”‚       â”œâ”€â”€ train.csv    # Your training data
â”‚       â”œâ”€â”€ test.csv     # Your test data
â”‚       â””â”€â”€ holdout.csv  # (optional)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_processing/
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ training/
â”‚   â””â”€â”€ utils/
â””â”€â”€ scripts/
    â””â”€â”€ colab_pipeline.py   # The GPU pipeline
```

---

## âš™ï¸ Pre-configured Hyperparameters

The pipeline uses these optimal parameters (found via 250 Optuna trials):
```python
{
    "booster": "gbtree",
    "max_depth": 7,
    "eta": 0.296,
    "n_estimators": 900,
    "subsample": 0.76,
    "colsample_bytree": 0.99,
    "colsample_bylevel": 0.78,
    "min_child_weight": 6,
    "lambda": 0.00032,
    "alpha": 0.00017,
    "gamma": 0.00017
}
```

---

## ðŸ“¥ Download Your Trained Model

After training completes:
```python
from google.colab import files
files.download('models/best_model.pkl')
```

---

## ðŸ” Verify GPU is Working

```python
# Quick GPU check
!nvidia-smi

# Or in Python
import xgboost as xgb
try:
    xgb.XGBClassifier(tree_method='hist', device='cuda')
    print("âœ“ GPU is available")
except:
    print("âš  GPU not available")
```

---

## â±ï¸ Expected Training Time

With Colab GPU (T4):
- **Without Optuna:** ~2-5 minutes
- **With Optuna (250 trials):** ~30-60 minutes

Our pipeline skips Optuna, so expect **~2-5 minutes total runtime**!

---

## ðŸ“Š Monitoring Training

The pipeline will display:
- Data loading progress
- Feature engineering steps
- Training metrics (recall, precision, F1)
- MLflow experiment tracking
- Model save location

---

## ðŸŽ¯ Customization Options

Edit `scripts/colab_pipeline.py` to change:

```python
# In ColabPipelineConfig class:
THRESHOLD_VALUE = 0.35        # Decision threshold (lower = catch more churners)
OPTIMIZE_METRIC = "recall"    # Metric to optimize
PREPROCESSING_STRATEGY = "median"  # Handling missing values
```

To run Optuna optimization (takes longer):
```python
# Set BEST_PARAMS = None in config
# The pipeline will automatically run Optuna
```

---

## ðŸ› Troubleshooting

### GPU Not Detected
- Check Runtime > Change runtime type > GPU is selected
- Restart runtime: Runtime > Restart runtime
- Verify with `!nvidia-smi`

### Module Not Found
```python
# Make sure you're in the right directory
%cd /content/sales-data-churn

# Reinstall packages
!pip install --upgrade xgboost scikit-learn mlflow
```

### Out of Memory
- Reduce `n_estimators` from 900 to 500
- Use smaller dataset for testing
- Restart runtime to clear memory

---

## ðŸ“š Additional Resources

- [XGBoost GPU Support](https://xgboost.readthedocs.io/en/latest/gpu/index.html)
- [Google Colab GPU Guide](https://colab.research.google.com/notebooks/gpu.ipynb)
- [MLflow Tracking](https://mlflow.org/docs/latest/tracking.html)

---

## âœ¨ Tips for Colab

1. **Save work periodically** - Colab sessions timeout after inactivity
2. **Connect to Drive** - Store results in Google Drive for persistence
3. **Use GPU wisely** - Free tier has usage limits
4. **Download models** - Before session ends

---

Happy Training! ðŸŽ‰
